:py:mod:`OSmOSE`
================

.. py:module:: OSmOSE


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   cluster/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   Dataset/index.rst
   Spectrogram/index.rst
   config/index.rst
   job/index.rst
   timestamps/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   OSmOSE.Dataset
   OSmOSE.Job_builder
   OSmOSE.Spectrogram



Functions
~~~~~~~~~

.. autoapisummary::

   OSmOSE.write_timestamp



.. py:class:: Dataset(dataset_path: str, *, gps_coordinates: Union[str, list, Tuple] = None, owner_group: str = None, original_folder: str = None)

   .. py:property:: name

      
      The Dataset name. It is readonly.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: path

      
      The Dataset path. It is readonly.

      :type: Path















      ..
          !! processed by numpydoc !!

   .. py:property:: original_folder

      
      The folder containing the original audio file.

      :type: Path















      ..
          !! processed by numpydoc !!

   .. py:property:: gps_coordinates
      :type: Union[Tuple[float, float], Tuple[Tuple[float, float], Tuple[float, float]]]

      
      The GPS coordinates of the listening location. First element is latitude, second is longitude.

      GPS coordinates are used to localize the dataset and required for some utilities, like the
      weather and environment utility.















      ..
          !! processed by numpydoc !!

   .. py:property:: owner_group

      
      The Unix group able to interact with the dataset.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: is_built

      
      Checks if self.path/data/audio contains at least one folder and none called "original".
















      ..
          !! processed by numpydoc !!

   .. py:method:: build(*, original_folder: str = None, owner_group: str = None, date_template: str = None, bare_check: bool = False, auto_normalization: bool = False, force_upload: bool = False) -> OSmOSE.config.Path

      
      Set up the architecture of the dataset.

      The following operations will be performed on the dataset. None of them are destructive:
          - open and read the header of audio files located in `raw/audio/original/`.
          - rename files containing illegal characters.
          - generate some stastics regarding the files and dataset durations.
          - write the raw/metadata.csv file.
          - Identify and record files with anomalies (short duration, unreadable header...).
          - Set the permission of the dataset to the osmose group.

      :param original_folder: The name of the folder containing the original audio file. It is named "original" by convention.
                              If none is passed, the program expects to find either only one folder in the dataset audio folder, or
                              a folder named `original`
      :type original_folder: `str`, optional, keyword-only
      :param owner_group: The name of the group using the osmose dataset. It will have all permissions over the dataset.
      :type owner_group: `str`, optional, keyword_only
      :param date_template: the date template in strftime format. For example, `2017/02/24` has the template `%Y/%m/%d`.
                            It is used to generate automatically the timestamp.csv file. Alternatively, you can call the script to create the timestamp file first.
                            If no template is provided, will assume that the file already exists. In future versions, the template will be guessed automatically.
                            For more information on strftime template, see https://strftime.org/.
      :type date_template: `str`, optional, keyword_only
      :param bare_check: Only do the checks and build steps that requires low resource usage. If you build the dataset on a login node or
                         if you are sure it is already good to use, set to True. Otherwise, it should be inside a job. Default is False.
      :type bare_check: `bool`, optional, keyword_only
      :param auto_normalization: If true, automatically normalize audio files if the data would cause issues downstream. The default is False.
      :type auto_normalization: `bool`, optional, keyword_only
      :param force_upload: If true, ignore the file anomalies and build the dataset anyway. The default is False.
      :type force_upload: `bool`, optional, keyword_only

      :returns: **dataset** -- The dataset object.
      :rtype: `Dataset`

      .. rubric:: Example

      >>> from pathlib import Path
      >>> from OSmOSE import Dataset
      >>> dataset = Dataset(Path("home","user","my_dataset"))
      >>> dataset.build()

      DONE ! your dataset is on OSmOSE platform !















      ..
          !! processed by numpydoc !!

   .. py:method:: delete_abnormal_files() -> None

      
      Delete all files with abnormal durations in the dataset, and rewrite the timestamps.csv file to reflect the changes.
      If no abnormal file is detected, then it does nothing.
















      ..
          !! processed by numpydoc !!

   .. py:method:: _find_or_create_original_folder() -> OSmOSE.config.Path

      
      Gather all wav files in the original folder, and search for the corresponding timestamp.csv file.

      :returns: **original_folder** -- The path to the folder containing the original files.
      :rtype: `Path`

      :raises ValueError: If the original folder is not found and could not be created.















      ..
          !! processed by numpydoc !!

   .. py:method:: _get_original_after_build() -> OSmOSE.config.Path

      
      Find the original folder path after the dataset has been built.

      :returns: **original_folder** -- The path to the folder containing the original audio file.
      :rtype: `Path`

      :raises ValueError: If no metadata.csv has been found and the original folder is not able to be found.















      ..
          !! processed by numpydoc !!

   .. py:method:: __str__()

      
      Return str(self).
















      ..
          !! processed by numpydoc !!


.. py:function:: write_timestamp(*, audio_path: str, date_template: str, timezone: str = 'UTC', offsets: tuple = None)

   
   Read the dates in the filenames of audio files in the `audio_path` folder,
   according to the date template in strftime format or the offsets from the beginning and end of the date.

   If both `date_template` and `offsets` are provided, the latter has priority and `date_template` is ignored.

   The result is written in a file named `timestamp.csv` with no header and two columns in this format : [filename],[timestamp].
   The output date is in the template `'%Y-%m-%dT%H:%M:%S.%fZ'.

   :param audio_path: the path of the folder containing audio files
   :type audio_path: `str`
   :param date_template: the date template in strftime format. For example, `2017/02/24` has the template `%Y/%m/%d`
                         For more information on strftime template, see https://strftime.org/
   :type date_template: `str`
   :param timezone: The timezone this timestamp was originally recorded in (the default is UTC).
   :type timezone: `str`, optional
   :param offsets: a tuple containing the beginning and end offset of the date.
                   The first element is the first character of the date, and the second is the last.
   :type offsets: `tuple(int,int)`, optional















   ..
       !! processed by numpydoc !!

.. py:class:: Job_builder(config_file: str = None)

   .. py:property:: config
      :type: dict


   .. py:property:: prepared_jobs


   .. py:property:: ongoing_jobs


   .. py:property:: finished_jobs


   .. py:property:: job_scheduler


   .. py:property:: env_script


   .. py:property:: env_name


   .. py:property:: queue


   .. py:property:: nodes


   .. py:property:: walltime


   .. py:property:: ncpus


   .. py:property:: mem


   .. py:property:: outfile


   .. py:property:: errfile


   .. py:method:: write_configuration(output_file: str = None)

      
      Writes the configuration to the original configuration file, or a new file if specified.
















      ..
          !! processed by numpydoc !!

   .. py:method:: build_job_file(*, script_path: str, script_args: str, jobname: str = None, preset: Literal[low, medium, high] = None, job_scheduler: Literal[Torque, Slurm] = None, env_script: str = None, env_name: str = None, queue: str = None, nodes: int = None, walltime: str = None, ncpus: int = None, mem: str = None, outfile: str = None, errfile: str = None, logdir: OSmOSE.config.Path = None) -> str

      
      Build a job file corresponding to your job scheduler.

      When a job file is created, it becomes a `prepared_job` and can be launched automatically using the `submit_job()` method
      with no arguments.

      This method can use the configuration file to set default job parameters. Use presets to quickly adjust the resource
      consumption or fill the parameters. If a parameter is left empty, it will fall back to the value in the configuration file.
      The default preset is `low` in order to save as much resource as possible.

      :param script_path: The path to the script that will be executed in the cluster job
      :type script_path: `str`, keyword-only
      :param script_args: All the arguments required by the script, as one string.
      :type script_args: `str`, keyword-only
      :param jobname: The name of the job as seen on the job list (qstat, squeue, ...). The default is the script name.
      :type jobname: `str`, optional, keyword-only
      :param preset: Resource preset for the job. It is best to set up the presets in the configuration file before using them,
                     as the default might not correspond to your structure. The default is `low`.
      :type preset: `{"low", "medium", "high"}`, optional, keyword-only
      :param job_scheduler: The job scheduler to which the jobs will be submitted. As of now, only Torque (PBS) and Slurm (Sbatch) are supported.
      :type job_scheduler: `{"Torque", "Slurm"}`, optional, keyword-only
      :param env_script: The script used to activate the conda environment. If there is no particular script, it can just be `source` or `conda activate`
      :type env_script: `str`, optional, keyword-only
      :param env_name: The name of the conda environment this job should run into.
      :type env_name: `str`, optional, keyword-only
      :param queue: The partition/queue/qol in which the job should run. It is very dependant on the cluster.
      :type queue: `str`, optional, keyword-only
      :param nodes: The number of nodes (i.e. computers) this job will use. If it is not using a protocol like MPI or an adapted job scheduler (like PEGASUS),
                    using more than one node will have no effect.
      :type nodes: `int`, optional, keyword-only
      :param walltime: The time limit of the job. If exceeded, the job will be killed by the job scheduler. It is best to view large and ask for 1.5 or 2 times
                       more than the anticipated time of the job, especially for tasks with a high degree ofo variability in processing time.
      :type walltime: `str`, optional, keyword-only
      :param ncpus: The number of CPUs required per node.
      :type ncpus: `int`, optional, keyword-only
      :param mem: The quantity of RAM required per CPU. Most of the time it is an integer followed by a G for Gigabytes or Mb for Megabytes.
      :type mem: `str`, optional, keyword-only
      :param outfile: The name of the main log file which will record the standard output from the job. If only the name is provided, it will be created in the current
                      directory.
      :type outfile: `str`, optional, keyword-only
      :param errfile: The name of the error log file which will record the error output from the job. If only the name is provided, it will be created in the
                      current directory. If there is no error output, it will not be created.
      :type errfile: `str`, optional, keyword-only

      :returns: **job_path** -- The path to the created job file.
      :rtype: `str`















      ..
          !! processed by numpydoc !!

   .. py:method:: submit_job(jobfile: str = None, dependency: str | List[str] = None) -> List[str]

      
      Submits the job file to the cluster using the job scheduler written in the file name or in the configuration file.
















      ..
          !! processed by numpydoc !!

   .. py:method:: update_job_status()

      
      Iterates over the list of ongoing jobs and mark them as finished if the job file does not exist.
















      ..
          !! processed by numpydoc !!

   .. py:method:: update_job_access()

      
      In case the output files are not accessible by anyone but the owner, running this once will update the permissions for anyone to read them.
















      ..
          !! processed by numpydoc !!

   .. py:method:: read_output_file(*, outtype: Literal[out, err] = 'out', job_file_name: str = None)

      
      Read the content of a specific job output file, or the first in the finished list.

      :param outtype: The type of the output file to read, whether standard (out) or error (err). The default is out.
      :type outtype: `{"out","err"}`, optional, keyword-only
      :param job_file_name: The path to the job_file to read, which can be retrieved easily from Job_builder.finished_jobs. If not provided, then the first element of the list will be read.
      :type job_file_name: `str`, optional, keyword-only















      ..
          !! processed by numpydoc !!


.. py:class:: Spectrogram(dataset_path: str, *, sr_analysis: int, gps_coordinates: Union[str, list, tuple] = None, owner_group: str = None, analysis_params: dict = None, batch_number: int = 10, local: bool = False)

   Bases: :py:obj:`OSmOSE.Dataset.Dataset`

   .. py:property:: sr_analysis

      
      The sampling frequency of the dataset.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: nfft

      
      The number of Fast Fourier Transform used to generate the spectrograms.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: window_size

      
      The window size of the generated spectrograms.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: overlap

      
      The overlap percentage between two spectrogram windows.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: colormap

      
      The type of colormap of the spectrograms.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: zoom_level

      
      Number of zoom levels.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: dynamic_min

      
      Minimum value of the colormap.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: dynamic_max

      
      Maximum value of the colormap.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: number_adjustment_spectrogram

      
      Number of spectrograms used to adjust the parameters.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: spectro_duration

      
      Duration of the spectrogram (at the lowest zoom level) in seconds.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: zscore_duration


   .. py:property:: HPfilter_min_freq

      
      Floor frequency for the High Pass Filter.

      :type: float















      ..
          !! processed by numpydoc !!

   .. py:property:: sensitivity

      
      Numeric sensitivity of the recording device.

      :type: int















      ..
          !! processed by numpydoc !!

   .. py:property:: peak_voltage

      
      The maximum voltage of the device.

      :type: float















      ..
          !! processed by numpydoc !!

   .. py:property:: spectro_normalization

      
      Type of normalization used to generate the spectrograms.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: data_normalization

      
      Type of normalization applied to the data.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: gain_dB

      
      Gain of the device in decibels.

      :type: float















      ..
          !! processed by numpydoc !!

   .. py:property:: window_type

      
      Type of the window used to generate the spectrograms.

      :type: str















      ..
          !! processed by numpydoc !!

   .. py:property:: frequency_resolution


   .. py:property:: time_resolution


   .. py:method:: __build_path(adjust: bool = False, dry: bool = False)

      
      Build some internal paths according to the expected architecture and might create them.
















      ..
          !! processed by numpydoc !!

   .. py:method:: check_spectro_size()

      
      Verify if the parameters will generate a spectrogram that can fit one screen properly
















      ..
          !! processed by numpydoc !!

   .. py:method:: initialize(*, sr_analysis: int = None, reshape_method: Literal[legacy, classic, none] = 'none', batch_ind_min: int = 0, batch_ind_max: int = -1, pad_silence: bool = False, force_init: bool = False, date_template: str = None) -> None

      
      Prepares everything (path, variables, files) for spectrogram generation. This needs to be run before the spectrograms are generated.
      If the dataset has not yet been build, it is before the rest of the functions are initialized.

      :param sr_analysis: The sampling frequency of the audio files used to generate the spectrograms. If set, will overwrite the Spectrogram.sr_analysis attribute.
      :type sr_analysis: `int`, optional, keyword-only
      :param reshape_method: Which method to use if the desired size of the spectrogram is different from the audio file duration.
                             - legacy : Legacy method, use bash and sox software to trim the audio files and fill the empty space with nothing.
                             Unpractical when the audio file duration is longer than the desired spectrogram size.
                             - classic : Classic method, use python and sox library to cut and concatenate the audio files to fit the desired duration.
                             Will rewrite the `timestamp.csv` file, thus timestamps may have unexpected behavior if the concatenated files are not chronologically
                             subsequent.
                             - none : Don't reshape, will throw an error if the file duration is different than the desired spectrogram size. (It is the default behavior)
      :type reshape_method: {"legacy", "classic", "none"}, optional, keyword-only
      :param batch_ind_min: The index of the first file to consider. Both this parameter and `batch_ind_max` are not commonly used and are
                            for very specific use cases. Most of the time, you want to initialize the whole dataset (the default is 0).
      :type batch_ind_min: `int`, optional, keyword-only
      :param batch_ind_max: The index of the last file to consider (the default is -1, meaning consider every file).
      :type batch_ind_max: `int`, optional, keyword-only
      :param pad_silence: When using the legacy reshaping method, whether there should be a silence padding or not (default is False).
      :type pad_silence: `bool`, optional, keyword-only
      :param force_init: Force every parameter of the initialization.
      :type force_init: `bool`, optional, keyword-only
      :param date_template: When initializing a spectrogram of a dataset that has not been built, providing a date_template will generate the timestamp.csv.
      :type date_template: `str`, optiona, keyword-only















      ..
          !! processed by numpydoc !!

   .. py:method:: audio_file_list_csv() -> OSmOSE.config.Path


   .. py:method:: update_parameters(filename: OSmOSE.config.Path) -> bool

      
      Read the csv file filename and compare it to the spectrogram parameters. If any parameter is different, the file will be replaced and the fields changed.

      If there is nothing to update, the file won't be changed.















      ..
          !! processed by numpydoc !!

   .. py:method:: to_csv(filename: OSmOSE.config.Path) -> None

      
      Outputs the characteristics of the spectrogram the specified file in csv format.
















      ..
          !! processed by numpydoc !!

   .. py:method:: process_file(audio_file: Union[str, OSmOSE.config.Path], *, adjust: bool = False, save_matrix: bool = False, clean_adjust_folder: bool = False) -> None

      
      Read an audio file and generate the associated spectrogram.

      :param audio_file: The name of the audio file to be processed
      :type audio_file: `str` or `Path`
      :param adjust: Indicates whether the file should be processed alone to adjust the spectrogram parameters (the default is False)
      :type adjust: `bool`, optional, keyword-only
      :param save_matrix: Whether to save the spectrogram matrices or not. Note that activating this parameter might increase greatly the volume of the project. (the default is False)
      :type save_matrix: `bool`, optional, keyword-only
      :param clean_adjust_folder: Whether the adjustment folder should be deleted.
      :type clean_adjust_folder: `bool`, optional, keyword-only















      ..
          !! processed by numpydoc !!

   .. py:method:: gen_tiles(*, data: numpy.ndarray, sample_rate: int, output_file: OSmOSE.config.Path)

      
      Generate spectrogram tiles corresponding to the zoom levels.

      :param data: The audio data from which the tiles will be generated.
      :type data: `np.ndarray`
      :param sample_rate: The sample rate of the audio data.
      :type sample_rate: `int`
      :param output_file: The name of the output spectrogram.
      :type output_file: `str`















      ..
          !! processed by numpydoc !!

   .. py:method:: gen_spectro(*, data: numpy.ndarray, sample_rate: int, output_file: OSmOSE.config.Path) -> Tuple[numpy.ndarray, numpy.ndarray[float]]

      
      Generate the spectrograms

      :param data: The audio data from which the tiles will be generated.
      :type data: `np.ndarray`
      :param sample_rate: The sample rate of the audio data.
      :type sample_rate: `int`
      :param output_file: The name of the output spectrogram.
      :type output_file: `str`

      :returns: * **Sxx** (`np.NDArray[float64]`)
                * **Freq** (`np.NDArray[float]`)















      ..
          !! processed by numpydoc !!

   .. py:method:: generate_and_save_figures(*, time: numpy.ndarray[float], freq: numpy.ndarray[float], log_spectro: numpy.ndarray[int], output_file: OSmOSE.config.Path)

      
      Write the spectrogram figures to the output file.

      :param time:
      :type time: `np.NDArray[floating]`
      :param freq:
      :type freq: `np.NDArray[floating]`
      :param log_spectro:
      :type log_spectro: `np.NDArray[signed int]`
      :param output_file: The name of the spectrogram file.
      :type output_file: `str`















      ..
          !! processed by numpydoc !!

   .. py:method:: process_all_files(*, save_matrix: bool = False)

      
      Process all the files in the dataset and generates the spectrograms. It uses the python multiprocessing library
      to parallelise the computation, so it is less efficient to use this method rather than the job scheduler if run on a cluster.
















      ..
          !! processed by numpydoc !!


